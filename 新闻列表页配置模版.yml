description: >-
  Version: 2020_07_11_13_20_00

  ⚠️配置前请核对版本号是否最新; 带有✔️字段开始往下的字段需要配置, 页面中没有的字段删除即可; 测试时注意核验字段值的数据准确性:
  描述中有❤️标志的字段
proxy: default
normal_status_list:
  - '200'
login_id: ''
downloader: pycurl
min_data_length: 0
min_link_length: 1
timeout: 30
load_wait: 0
cache_ttl: 0
cache_after: 0
encoding: ''
headers: ''
download_script: ''
rows:
  - name: ❤️列表详情链接配置
    description: 注意保持字段与详情页对应
    locator: xpath
    expression: >-
      .//a[not(contains(translate(@href, "PDF", "pdf"), ".pdf") and
      contains(translate(@href, "XLS", "xls"), ".xls") and
      contains(translate(@href, "DOC", "doc"), ".doc"))]
    storage_id: -1
    if_match: ''
    if_url_match: ''
    fields:
      - name: web_site
        description: 来源网站
        data_type: varchar(1024)
        locator: hub
        expression: web_site
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors: []
        validators: []
        is_dedup_array: false
      - name: web_site_url
        description: 来源网站地址
        data_type: varchar(1024)
        locator: hub
        expression: web_site_url
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors: []
        validators:
          - method: script
            params: |-
              def validate(context):
                  """Version: 2020_07_11
                  验证链接是否合法
                  """
                  import re
                  from urllib.parse import urlparse

                  url = context.strip()
                  rules = [
                      r"(https?|ftp|file)://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]",
                      r"@^(https?|ftp)://[^\s/$.?#].[^\s]*$@iS",
                      r"#\b(([\w-]+://?|www[.])[^\s()<>]+(?:\([\w\d]+\)|([^[:punct:]\s]|/)))#iS",
                  ]
                  for each in rules:
                      p = re.compile(each)
                      res = p.findall(url)
                      if res:
                          return True
                  else:
                      try:
                          q = urlparse(url)
                      except:
                          return False
                      else:
                          if all([q.scheme, q.netloc, q.path]):
                              return True
                          else:
                              return False
            fail_type: retry
        is_dedup_array: false
      - name: refer
        description: "\U0001F494列表页链接上线需删除"
        data_type: varchar(128)
        locator: url_re
        expression: .*
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors: []
        validators:
          - method: script
            params: |-
              def validate(context):
                  """Version: 2020_07_11
                  验证链接是否合法
                  """
                  import re
                  from urllib.parse import urlparse

                  url = context.strip()
                  rules = [
                      r"(https?|ftp|file)://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]",
                      r"@^(https?|ftp)://[^\s/$.?#].[^\s]*$@iS",
                      r"#\b(([\w-]+://?|www[.])[^\s()<>]+(?:\([\w\d]+\)|([^[:punct:]\s]|/)))#iS",
                  ]
                  for each in rules:
                      p = re.compile(each)
                      res = p.findall(url)
                      if res:
                          return True
                  else:
                      try:
                          q = urlparse(url)
                      except:
                          return False
                      else:
                          if all([q.scheme, q.netloc, q.path]):
                              return True
                          else:
                              return False
            fail_type: retry
        is_dedup_array: false
      - name: title
        description: "\U0001F49A标题"
        data_type: varchar(1024)
        locator: xpath
        expression: .
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors: []
        validators: []
        is_dedup_array: false
      - name: publish_time
        description: ❤️新闻发布时间
        data_type: varchar(1024)
        locator: xpath
        expression: .
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors:
          - method: script
            params: |-
              def process(text):
                  """Version: 2020_07_11
                  时间提取脚本模版
                  """
                  import re
                  from datetime import datetime
                  data = text.strip()

                  rules = [
                      r"\d{4}[-年/]\d{1,2}[-月/]\d{1,2}[-日/]?[\s\d{2}:\d{2}[:\d{2}]?]?",  # 常见中文日期格式
                      # r"\d{10}",  # TODO: 处理时间戳, 遇到再加: 15开头的10或13位数字, 其实匹配前10个就够了
                      r"",     # 如有不是常见的日期时间格式，此处替换成案例
                  ]
                  # 无内容时间返回空
                  if not data:
                      return "error:空字符串"
                  # 预处理，替换掉会影响正则提取的固定字符串, 如点击量的数字
                  flags = [""]
                  for each in flags:
                      data = data.replace(each, "")
                  # 提取日期时间
                  for each in rules:
                      p = re.compile(each)
                      res = p.findall(data)
                      if res:
                          return res[0]
                      else:
                          continue
                  else:
                      return f"error:{text}"
          - method: text2datetime
            params: ''
        validators:
          - method: script
            params: |
              def validate(context):
                  """Version: 2020_07_11
                  验证发布时间是否大于当前时间
                  """
                  from datetime import datetime

                  if context.startswith("error:"):
                      return False
                  else:
                      now = datetime.now()
                      pt = datetime.strptime(context, "%Y-%m-%d %H:%M:%S")
                      if pt > now:
                          return False
                      return True
            fail_type: retry
        is_dedup_array: false
      - name: tag
        description: ❤️标签
        data_type: varchar(1024)
        locator: xpath
        expression: .
        is_dedup_key: false
        multi: true
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors: []
        validators:
          - method: script
            params: |-
              def validate(context):
                  """Version: 2020_07_11
                  TODO: 验证标签, 不同网站调整长度, 测试一段时间
                  """
                  import re

                  text = context.strip()
                  # 验证长度
                  if len(text) > 5 or len(text) < 2:
                      return False
                  # 验证是否是含有非中文字符
                  rules = [r"[\u4e00-\u9fa5]+"]
                  for each in rules:
                      p = re.compile(each)
                      res = p.match(text)
                      if res:
                          if res[0] == text:
                              return True
                          else:
                              return False
                  else:
                      return False
            fail_type: retry
        is_dedup_array: false
      - name: author
        description: ❤️作者
        data_type: varchar(1024)
        locator: xpath
        expression: .
        is_dedup_key: false
        multi: true
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors:
          - method: script
            params: |-
              def process(text):
                  """Version: 2020_07_11
                  作者提取脚本模版
                  returns:
                      []: 正则匹配失败
                  """
                  import re

                  author = text.strip()

                  # 按需排序
                  rules = [
                      r"\b([\u4e00-\u9fa5]\s?[\u4e00-\u9fa5]+)\b",  # 常见中文作者格式
                      r"([a-zA-Z0-9]+)",  # 作者为字母和数字组合
                      # r"",  # 如有不是常见的作者格式，此处替换成案例
                  ]
                  # 无内容作者返回空列表
                  if not author:
                      return []
                  # 预处理，替换掉会影响正则提取的固定字符串, 从验证器中更新
                  flags = ["记者", "撰文", "通讯员", "责任编辑", "编辑", "通讯中"]
                  for each in flags:
                      author = author.replace(each, "")
                  # 提取作者
                  for each in rules:
                      p = re.compile(each)
                      res = p.findall(author)
                      if res:
                          return [i.replace(" ", "") for i in res]
                      else:
                          continue
                  else:
                      return [f"error:{text}"]
        validators:
          - method: script
            params: |-
              def validate(context):
                  """Version: 2020_07_11
                  验证中文作者是否含有非法词
                  """
                  if context.startswith("error:"):
                      return False
                  elif len(context) > 4 or len(context) < 2:
                      return False
                  return True
            fail_type: retry
        is_dedup_array: false
      - name: author_info
        description: 作者简介
        data_type: varchar(1024)
        locator: xpath
        expression: .
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors: []
        validators: []
        is_dedup_array: false
      - name: abstract
        description: 新闻摘要
        data_type: varchar(1024)
        locator: xpath
        expression: .
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors: []
        validators: []
        is_dedup_array: false
    links:
      - page_rule_id: null
        new_task_name: ''
        description: 详情页链接
        locator: xpath
        expression: ./@href
        processors: []
        keep_other_site: false
  - name: "\U0001F4C1文件链接配置"
    description: 解析文件链接
    locator: xpath
    expression: >-
      .//a[(contains(translate(@href, "PDF", "pdf"), ".pdf") or
      contains(translate(@href, "XLS", "xls"), ".xls") or
      contains(translate(@href, "DOC", "doc"), ".doc")) and not(contains(@href,
      "file://"))]
    storage_id: 10270
    if_match: ''
    if_url_match: ''
    fields:
      - name: web_site
        description: 来源网站
        data_type: varchar(1024)
        locator: hub
        expression: web_site
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors: []
        validators:
          - method: length
            params: 1 +inf
            fail_type: retry
        is_dedup_array: false
      - name: web_site_url
        description: 来源网站地址
        data_type: varchar(1024)
        locator: hub
        expression: web_site_url
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors: []
        validators:
          - method: script
            params: |-
              def validate(context):
                  """Version: 2020_07_11
                  验证链接是否合法
                  """
                  import re
                  from urllib.parse import urlparse

                  url = context.strip()
                  rules = [
                      r"(https?|ftp|file)://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]",
                      r"@^(https?|ftp)://[^\s/$.?#].[^\s]*$@iS",
                      r"#\b(([\w-]+://?|www[.])[^\s()<>]+(?:\([\w\d]+\)|([^[:punct:]\s]|/)))#iS",
                  ]
                  for each in rules:
                      p = re.compile(each)
                      res = p.findall(url)
                      if res:
                          return True
                  else:
                      try:
                          q = urlparse(url)
                      except:
                          return False
                      else:
                          if all([q.scheme, q.netloc, q.path]):
                              return True
                          else:
                              return False
            fail_type: retry
        is_dedup_array: false
      - name: content_md5
        description: 用来去重的md5
        data_type: varchar(1024)
        locator: hub
        expression: web_site
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors: []
        validators:
          - method: length
            params: 1 +inf
            fail_type: retry
        is_dedup_array: false
      - name: content_url
        description: 正文详情url
        data_type: varchar(1024)
        locator: xpath
        expression: ./@href
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: true
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors: []
        validators:
          - method: script
            params: |-
              def validate(context):
                  """Version: 2020_07_11
                  验证链接是否合法
                  """
                  import re
                  from urllib.parse import urlparse

                  url = context.strip()
                  rules = [
                      r"(https?|ftp|file)://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]",
                      r"@^(https?|ftp)://[^\s/$.?#].[^\s]*$@iS",
                      r"#\b(([\w-]+://?|www[.])[^\s()<>]+(?:\([\w\d]+\)|([^[:punct:]\s]|/)))#iS",
                  ]
                  for each in rules:
                      p = re.compile(each)
                      res = p.findall(url)
                      if res:
                          return True
                  else:
                      try:
                          q = urlparse(url)
                      except:
                          return False
                      else:
                          if all([q.scheme, q.netloc, q.path]):
                              return True
                          else:
                              return False
            fail_type: retry
        is_dedup_array: false
      - name: title
        description: 标题
        data_type: varchar(1024)
        locator: xpath
        expression: .
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors: []
        validators:
          - method: length
            params: 1 +inf
            fail_type: retry
        is_dedup_array: false
      - name: article_file_name
        description: 附件名称
        data_type: varchar(1024)
        locator: xpath
        expression: .
        is_dedup_key: false
        multi: true
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: true
        download_policy: not_download
        processors: []
        validators:
          - method: length
            params: 1 +inf
            fail_type: retry
        is_dedup_array: false
      - name: article_file_url
        description: 附件地址
        data_type: varchar(1024)
        locator: xpath
        expression: ./@href
        is_dedup_key: false
        multi: true
        keep_html: false
        extend_url: true
        is_extra: false
        allow_invalid_expression: true
        download_policy: not_download
        processors: []
        validators:
          - method: script
            params: |-
              def validate(context):
                  """Version: 2020_07_11
                  验证链接是否合法
                  """
                  import re
                  from urllib.parse import urlparse

                  url = context.strip()
                  rules = [
                      r"(https?|ftp|file)://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]",
                      r"@^(https?|ftp)://[^\s/$.?#].[^\s]*$@iS",
                      r"#\b(([\w-]+://?|www[.])[^\s()<>]+(?:\([\w\d]+\)|([^[:punct:]\s]|/)))#iS",
                  ]
                  for each in rules:
                      p = re.compile(each)
                      res = p.findall(url)
                      if res:
                          return True
                  else:
                      try:
                          q = urlparse(url)
                      except:
                          return False
                      else:
                          if all([q.scheme, q.netloc, q.path]):
                              return True
                          else:
                              return False
            fail_type: retry
        is_dedup_array: false
      - name: refer
        description: "\U0001F494列表页链接上线需删除"
        data_type: varchar(128)
        locator: url_re
        expression: .*
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors: []
        validators:
          - method: script
            params: |-
              def validate(context):
                  """Version: 2020_07_11
                  验证链接是否合法
                  """
                  import re
                  from urllib.parse import urlparse

                  url = context.strip()
                  rules = [
                      r"(https?|ftp|file)://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]",
                      r"@^(https?|ftp)://[^\s/$.?#].[^\s]*$@iS",
                      r"#\b(([\w-]+://?|www[.])[^\s()<>]+(?:\([\w\d]+\)|([^[:punct:]\s]|/)))#iS",
                  ]
                  for each in rules:
                      p = re.compile(each)
                      res = p.findall(url)
                      if res:
                          return True
                  else:
                      try:
                          q = urlparse(url)
                      except:
                          return False
                      else:
                          if all([q.scheme, q.netloc, q.path]):
                              return True
                          else:
                              return False
            fail_type: retry
        is_dedup_array: false
      - name: news_type
        description: "\U0001F49A新闻类型（资讯，公告，纰漏）"
        data_type: varchar(1024)
        locator: xpath
        expression: .
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors:
          - method: script
            params: |-
              def process(text):
                  """
                  处理文本, 返回处理后的文本
                  """
                  return text
        validators:
          - method: length
            params: 1 +inf
            fail_type: retry
        is_dedup_array: false
      - name: publish_time
        description: ❤️新闻发布时间
        data_type: datetime
        locator: xpath
        expression: .
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors:
          - method: script
            params: |-
              def process(text):
                  """Version: 2020_07_11
                  时间提取脚本模版
                  """
                  import re
                  from datetime import datetime
                  data = text.strip()

                  rules = [
                      r"\d{4}[-年/]\d{1,2}[-月/]\d{1,2}[-日/]?[\s\d{2}:\d{2}[:\d{2}]?]?",  # 常见中文日期格式
                      # r"\d{10}",  # TODO: 处理时间戳, 遇到再加: 15开头的10或13位数字, 其实匹配前10个就够了
                      r"",     # 如有不是常见的日期时间格式，此处替换成案例
                  ]
                  # 无内容时间返回空
                  if not data:
                      return "error:空字符串"
                  # 预处理，替换掉会影响正则提取的固定字符串, 如点击量的数字
                  flags = [""]
                  for each in flags:
                      data = data.replace(each, "")
                  # 提取日期时间
                  for each in rules:
                      p = re.compile(each)
                      res = p.findall(data)
                      if res:
                          return res[0]
                      else:
                          continue
                  else:
                      return f"error:{text}"
          - method: text2datetime
            params: ''
        validators:
          - method: script
            params: |-
              def validate(context):
                  """Version: 2020_07_11
                  验证发布时间是否大于当前时间
                  """
                  from datetime import datetime

                  if context.startswith("error:"):
                      return False
                  else:
                      now = datetime.now()
                      pt = datetime.strptime(context, "%Y-%m-%d %H:%M:%S")
                      if pt > now:
                          return False
                      return True
            fail_type: retry
        is_dedup_array: false
      - name: publish_org
        description: ❤️新闻发布来源
        data_type: varchar(1024)
        locator: xpath
        expression: .
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors:
          - method: script
            params: |-
              def process(text):
                  """Version: 2020_07_11
                  来源提取
                  """
                  import re

                  # 按需排序
                  rules = [
                      r"([\u4e00-\u9fa5]+)",  # 默认提取中文, 其它格式卡住后处理
                      # r"", # 自定义
                      # r"([^\s/$.?].[^\s]*)", # www.railwaygazette.com
                  ]
                  # 无内容作者返回空列表
                  if not text.strip():
                      return []
                  # 预处理，替换掉会影响正则提取的固定字符串, 从验证器中更新
                  flags = ["来源", "转自"]
                  for each in flags:
                      text = text.replace(each, "")
                  # 提取来源
                  for each in rules:
                      p = re.compile(each)
                      res = p.findall(text)
                      if res:
                          return res[0]
                      else:
                          continue
                  else:
                      return f"error:[{text}]"
        validators:
          - method: script
            params: |-
              def validate(context):
                  """Version: 2020_07_11
                  验证来源中是否有error: 
                      卡住未经正确处理的请求
                  """
                  if context.startswith("error:"):
                      return False
                  return True
            fail_type: retry
        is_dedup_array: false
      - name: author
        description: ❤️作者
        data_type: varchar(1024)
        locator: xpath
        expression: .
        is_dedup_key: false
        multi: true
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors:
          - method: script
            params: |-
              def process(text):
                  """Version: 2020_07_11
                  作者提取脚本模版
                  returns:
                      []: 正则匹配失败
                  """
                  import re

                  author = text.strip()

                  # 按需排序
                  rules = [
                      r"\b([\u4e00-\u9fa5]\s?[\u4e00-\u9fa5]+)\b",  # 常见中文作者格式
                      r"([a-zA-Z0-9]+)",  # 作者为字母和数字组合
                      # r"",  # 如有不是常见的作者格式，此处替换成案例
                  ]
                  # 无内容作者返回空列表
                  if not author:
                      return []
                  # 预处理，替换掉会影响正则提取的固定字符串, 从验证器中更新
                  flags = ["记者", "撰文", "通讯员", "责任编辑", "编辑", "通讯中"]
                  for each in flags:
                      author = author.replace(each, "")
                  # 提取作者
                  for each in rules:
                      p = re.compile(each)
                      res = p.findall(author)
                      if res:
                          return [i.replace(" ", "") for i in res]
                      else:
                          continue
                  else:
                      return [f"error:{text}"]
        validators:
          - method: script
            params: |-
              def validate(context):
                  """Version: 2020_07_11
                  验证中文作者是否含有非法词
                  """
                  if context.startswith("error:"):
                      return False
                  elif len(context) > 4 or len(context) < 2:
                      return False
                  return True
            fail_type: retry
        is_dedup_array: false
      - name: tag
        description: ❤️标签
        data_type: varchar(1024)
        locator: xpath
        expression: .
        is_dedup_key: false
        multi: true
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors: []
        validators:
          - method: script
            params: |-
              def validate(context):
                  """Version: 2020_07_11
                  TODO: 验证标签, 不同网站调整长度, 测试一段时间
                  """
                  import re

                  text = context.strip()
                  # 验证长度
                  if len(text) > 5 or len(text) < 2:
                      return False
                  # 验证是否是含有非中文字符
                  rules = [r"[\u4e00-\u9fa5]+"]
                  for each in rules:
                      p = re.compile(each)
                      res = p.match(text)
                      if res:
                          if res[0] == text:
                              return True
                          else:
                              return False
                  else:
                      return False
            fail_type: retry
        is_dedup_array: false
      - name: abstract
        description: 新闻摘要
        data_type: varchar(1024)
        locator: xpath
        expression: .
        is_dedup_key: false
        multi: false
        keep_html: false
        extend_url: false
        is_extra: false
        allow_invalid_expression: false
        download_policy: not_download
        processors: []
        validators:
          - method: length
            params: 1 +inf
            fail_type: retry
        is_dedup_array: false
    processors:
      - method: script
        params: |-
          import hashlib


          def md5(text):
              return hashlib.md5(str(text).encode()).hexdigest()


          def process(data):
              """Version: 2020_07_11
              计算网站名发布时间标题内容详情的MD5
              # TODO: 数组字段去重处理
              """
              data["content_md5"] = md5(
                  data["web_site"]
                  + data["publish_time"]
                  + data["title"]
                  + data.get("content", "")  # 空字符串到这里会变成None
              )

              return data
    links: []
preprocessors: []
prevalidators:
  - method: regex
    params: '^(?!.*[200|code]).*$'
    fail_type: success
    succ_type: ignore
    target: status_code
examples:
  - method: GET
    url: ''
    data: ''
    description: 配置测试始终保存勿删除
    should_save_sync: false
  - method: GET
    url: ''
    data: ''
    description: 异常测试说明：
    should_save_sync: false
  - method: GET
    url: ''
    data: ''
    description: 异常测试说明：
    should_save_sync: false
size: small
global_dedup: false
captcha: {}
use_bot: false
